{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "638c91d7-847f-4618-8d01-7ecc20b4832c",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## 5. Data cleaning & Normalization\n",
    "\n",
    "This file creates the final allpredictors table for all stations within the study area. We remove no data values and normalize the the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0f8699-d917-4ee7-aa7e-a00146688779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "from os.path import join as pjoin # Joining file directories\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a66059cd-29fa-4ddd-a50c-b886329896d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your working directory and go there\n",
    "work_dir = \"data\"\n",
    "os.chdir(work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e95633-f221-4f60-9faa-2450363f7f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"raw_data/predictors/combined/\"\n",
    "output_folder = \"raw_data/predictors/allpredictors/\"\n",
    "file_pattern = f\"{folder}/*.csv\"\n",
    "file_list = glob.glob(file_pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9781ba0-445c-4e44-8847-f6f23abb60a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Check number of no data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a98b08b-caff-4aab-9731-114c47ddf1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               6139391  6139400  6140400  6140401  6221100  6221101  6221102   \n",
      "Unnamed: 0         0.0      0.0        0        0        0        0        0  \\\n",
      "datetime           0.0      0.0        0        0        0        0        0   \n",
      "meteo_rain         0.0      0.0        0        0        0        0        0   \n",
      "meteo_tair         0.0      0.0        0        0        0        0        0   \n",
      "wg3_dis            0.0      0.0        0        0        0        0        0   \n",
      "wg3_RootMoist      0.0      0.0        0        0        0        0        0   \n",
      "wg3_SurfStor       0.0      0.0        0        0        0        0        0   \n",
      "wg3_SWE            0.0      0.0        0        0        0        0        0   \n",
      "lis_dis            0.0      0.0        0        0        0        0        0   \n",
      "lis_SurfMoist      0.0      0.0        0        0        0        0        0   \n",
      "lis_SWE            0.0      0.0        0        0        0        0        0   \n",
      "pcr_dis            0.0      0.0        0        0        0        0        0   \n",
      "pcr_SurfMoist      0.0      0.0        0        0        0        0        0   \n",
      "pcr_SurfStor       0.0      0.0        0        0        0        0        0   \n",
      "pcr_SWE            0.0      0.0        0        0        0        0        0   \n",
      "obs                NaN      NaN        0        0      204      204      132   \n",
      "\n",
      "               6242100  6242300  6242401  ...  6935050  6935051  6935052   \n",
      "Unnamed: 0         0.0      0.0      0.0  ...        0        0        0  \\\n",
      "datetime           0.0      0.0      0.0  ...        0        0        0   \n",
      "meteo_rain         0.0      0.0      0.0  ...        0        0        0   \n",
      "meteo_tair         0.0      0.0      0.0  ...        0        0        0   \n",
      "wg3_dis            0.0      0.0      0.0  ...        0        0        0   \n",
      "wg3_RootMoist      0.0      0.0      0.0  ...        0        0        0   \n",
      "wg3_SurfStor       0.0      0.0      0.0  ...        0        0        0   \n",
      "wg3_SWE            0.0      0.0      0.0  ...        0        0        0   \n",
      "lis_dis            0.0      0.0      0.0  ...        0        0        0   \n",
      "lis_SurfMoist      0.0      0.0      0.0  ...        0        0        0   \n",
      "lis_SWE            0.0      0.0      0.0  ...        0        0        0   \n",
      "pcr_dis            0.0      0.0      0.0  ...        0        0        0   \n",
      "pcr_SurfMoist      0.0      0.0      0.0  ...        0        0        0   \n",
      "pcr_SurfStor       0.0      0.0      0.0  ...        0        0        0   \n",
      "pcr_SWE            0.0      0.0      0.0  ...        0        0        0   \n",
      "obs                NaN      NaN      NaN  ...      336        0      204   \n",
      "\n",
      "               6935053  6935054  6935055  6935300  6935301  6935302  6939050  \n",
      "Unnamed: 0           0        0        0        0        0        0      0.0  \n",
      "datetime             0        0        0        0        0        0      0.0  \n",
      "meteo_rain           0        0        0        0        0        0      0.0  \n",
      "meteo_tair           0        0        0        0        0        0      0.0  \n",
      "wg3_dis              0        0        0        0        0        0      0.0  \n",
      "wg3_RootMoist        0        0        0        0        0        0      0.0  \n",
      "wg3_SurfStor         0        0        0        0        0        0      0.0  \n",
      "wg3_SWE              0        0        0        0        0        0      0.0  \n",
      "lis_dis              0        0        0        0        0        0      0.0  \n",
      "lis_SurfMoist        0        0        0        0        0        0      0.0  \n",
      "lis_SWE              0        0        0        0        0        0      0.0  \n",
      "pcr_dis              0        0        0        0        0        0      0.0  \n",
      "pcr_SurfMoist        0        0        0        0        0        0      0.0  \n",
      "pcr_SurfStor         0        0        0        0        0        0      0.0  \n",
      "pcr_SWE              0        0        0        0        0        0      0.0  \n",
      "obs                  0        0        0        0        0        0      NaN  \n",
      "\n",
      "[16 rows x 89 columns]\n"
     ]
    }
   ],
   "source": [
    "folder = \"predictors/combined/\"\n",
    "file_pattern = f\"{folder}/*.csv\"\n",
    "file_list = glob.glob(file_pattern)\n",
    "\n",
    "station_ids = []\n",
    "dataframes = []\n",
    "\n",
    "for file_name in file_list:\n",
    "    station_id = os.path.splitext(os.path.basename(file_name))[0].split(\"_\")[1]\n",
    "    df = pd.read_csv(file_name)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    \n",
    "    start_date = pd.to_datetime('1979-01-01')\n",
    "    end_date = pd.to_datetime('2012-12-01')\n",
    "\n",
    "    df_subset = df[(df['datetime'] >= start_date) & (df['datetime'] <= end_date)]\n",
    "    station_ids.append(station_id)\n",
    "    dataframes.append(df_subset)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "combined_df = pd.concat(dataframes, keys=station_ids)\n",
    "\n",
    "# Get the unique columns across all dataframes\n",
    "columns = combined_df.columns.unique()\n",
    "\n",
    "# Create a DataFrame to store the NaN sum for each column and station\n",
    "nan_sum = pd.DataFrame(index=columns)\n",
    "\n",
    "# Calculate the sum of NaN values for each variable/column and each station\n",
    "for station_id, df_subset in zip(station_ids, dataframes):\n",
    "    nan_sum[station_id] = df_subset.isna().sum()\n",
    "\n",
    "print(nan_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fc65d3-f0d3-4f50-bd71-b127c0db43fe",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Clean and normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087edede-2c3e-484b-83fb-50a3fc58db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_without_obs = []\n",
    "\n",
    "for file_name in file_list:\n",
    "    file = file_name.split(\"\\\\\")[-1]\n",
    "    \n",
    "    output_path = f'{output_folder}/{file}'\n",
    "    \n",
    "    station_id = int(os.path.splitext(os.path.basename(file_name))[0].split(\"_\")[1])\n",
    "    df = pd.read_csv(file_name)\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    \n",
    "    start_date = pd.to_datetime('1979-01-01')\n",
    "    end_date = pd.to_datetime('2012-12-01')\n",
    "\n",
    "    df_subset = df[(df['datetime'] >= start_date) & (df['datetime'] <= end_date)]\n",
    "    \n",
    "    if 'obs' not in df_subset.columns:\n",
    "        stations_without_obs.append(station_id)\n",
    "        continue\n",
    "        \n",
    "    # Columns to normalize\n",
    "    columns_to_normalize = ['meteo_rain', 'meteo_tair', 'wg3_RootMoist', 'wg3_SurfStor',\n",
    "                            'wg3_SWE', 'lis_SurfMoist', 'lis_SWE', 'pcr_SurfMoist',\n",
    "                            'pcr_SurfStor', 'pcr_SWE']\n",
    "\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    df_subset.dropna(axis=0, inplace=True)\n",
    "    \n",
    "    # Perform z-score normalization\n",
    "    scaler = StandardScaler()\n",
    "    normalized_data = df_subset.copy()  # Replace 'data' with your actual dataset\n",
    "    normalized_data[columns_to_normalize] = scaler.fit_transform(df_subset[columns_to_normalize])\n",
    "\n",
    "    \n",
    "    # Save cleaned dataframe to file\n",
    "    normalized_data.to_csv(output_path, index=False)\n",
    "\n",
    "print(len(stations_without_obs)) #These stations are not within the project study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b083c2-45f2-4916-b37d-485f5da6e347",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check again the NA's \n",
    "stations_with_missing_equal_total = []\n",
    "\n",
    "for station_id, df_subset in results.items():\n",
    "    num_observations = len(df_subset)\n",
    "    missing_counts = df_subset.isna().sum()\n",
    "    variables_with_missing_equal_total = missing_counts[missing_counts == num_observations].index.tolist()\n",
    "    \n",
    "    if variables_with_missing_equal_total:\n",
    "        stations_with_missing_equal_total.append(station_id)\n",
    "\n",
    "print(stations_with_missing_equal_total)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
