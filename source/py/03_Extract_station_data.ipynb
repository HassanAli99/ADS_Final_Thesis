{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "896295e1-061d-43e5-b987-e4f6cf2a004c",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## 3. Extracting data per stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4409ad6e-d631-4f5c-bcf1-f957d9ed1965",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required  packages\n",
    "import os  # File and directory operations\n",
    "from os.path import join as pjoin  # Joining file directories\n",
    "import time  # To measure the execution time of a code block in Python\n",
    "\n",
    "import subprocess  # Subprocess execution\n",
    "\n",
    "import numpy as np  # Numerical operations\n",
    "import pandas as pd  # Data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # Plotting\n",
    "\n",
    "import rasterio  # Raster data manipulation\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "\n",
    "from osgeo import gdal  # Geospatial Data Abstraction Library\n",
    "\n",
    "import pcraster as pcr  # PCRaster library\n",
    "\n",
    "import xarray as xr  # Multidimensional array manipulation\n",
    "from netCDF4 import Dataset  # NetCDF data manipulation\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "import math\n",
    "\n",
    "from multiprocess import Pool\n",
    "from concurrent import futures\n",
    "import glob\n",
    "import re\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c6e625-d56f-48a6-bc99-2c90fa045673",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'raw_data'\n",
    "os.chdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "308f86f2-ae01-46d6-9a4f-26ee99c552ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dir_or_make(path):\n",
    "    isExist = os.path.exists(path)\n",
    "    if not isExist:\n",
    "        # Create a new directory because it does not exist\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d68d0c5e-d13b-43c7-8f12-e904a34ad477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variables_to_csv(model, model_var):\n",
    "    filePath = f'{model}/upstream/upstream_timesteps'\n",
    "    outputpath = f'{model}/upstream_station_all'\n",
    "\n",
    "    file_pattern = '*.map'\n",
    "\n",
    "    # Get a list of all map files in the folder\n",
    "    file_list = glob.glob(os.path.join(filePath, file_pattern))\n",
    "\n",
    "    # Read the station latitude and longitude from a CSV file\n",
    "    loc = pd.read_csv('stationLatLon.csv')\n",
    "    loc = loc[(loc.wmo_reg == 6) & (loc.lat.between(45, 54.5)) & (loc.lon.between(4, 15.5))]\n",
    "\n",
    "    # Iterate over the stations\n",
    "    for station_idx, station_row in loc.iterrows():\n",
    "        lat = station_row['lon']\n",
    "        lon = station_row['lat']\n",
    "        station_no = station_row['grdc_no']\n",
    "\n",
    "        # Create a DataFrame for the current station\n",
    "        extracted_data = pd.DataFrame(columns=['datetime', model_var])\n",
    "\n",
    "        # Iterate over the map files\n",
    "        for file in file_list:\n",
    "            # Extract the base name and date from the file name\n",
    "            filename = os.path.basename(file)\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            date_part = base_name.split(\"_\")[-2:]\n",
    "\n",
    "            # Extract the year and month from the date part\n",
    "            year = date_part[0]\n",
    "            month = date_part[1]\n",
    "            date = f'{year}_{month}'\n",
    "\n",
    "            # Read the PCRaster map\n",
    "            pcr_map = pcr.readmap(file)\n",
    "\n",
    "            # Extract the value for the specific location\n",
    "            extracted_value = pcr.cellvalue_by_coordinates(pcr_map, lat, lon)[0]\n",
    "\n",
    "            # Check if the extracted value is NaN\n",
    "            if not pd.isna(extracted_value):\n",
    "                # Append the extracted value to the DataFrame\n",
    "                extracted_data = pd.concat([extracted_data, pd.DataFrame({'datetime': [date], model_var: [extracted_value]})],\n",
    "                                           ignore_index=True)\n",
    "\n",
    "\n",
    "        # Create a file path for the current station\n",
    "        station_csv = os.path.join(outputpath, f'{station_no}_{model_var}.csv')\n",
    "\n",
    "        # Save the DataFrame to a CSV file for the current station\n",
    "        extracted_data.to_csv(station_csv, index=False)\n",
    "\n",
    "# Call the function\n",
    "model = 'meteo'\n",
    "model_var = 'meteo_rain'\n",
    "extract_variables_to_csv(model, model_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ad5ab7-11ae-46cd-bdb4-78a5a35c1aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def near(array,value):\n",
    "    idx=(np.abs(array-value)).argmin()\n",
    "    return idx\n",
    "\n",
    "def get_latlon():  \n",
    "    \n",
    "    xin, yin = np.array(loc['lon']), np.array(loc['lat']) #real life lon, lat\n",
    "\n",
    "    lon = nc_sample.variables['x'][:]       #netcdf lon    \n",
    "    lat = nc_sample.variables['y'][:]       #netcdf lat\n",
    "    \n",
    "    #find nearest point to desired location\n",
    "    get_latlon.ix = [None] * len(xin)\n",
    "    get_latlon.iy = [None] * len(yin)\n",
    "    \n",
    "    for i in range(len(xin)):\n",
    "        get_latlon.ix[i] = near(lon, xin[i])\n",
    "        get_latlon.iy[i] = near(lat, yin[i])\n",
    "    get_latlon.ix = np.array(get_latlon.ix)\n",
    "    get_latlon.iy = np.array(get_latlon.iy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8a9f7fa-d2b6-4eb1-bf8d-26b5bebb716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_variables_to_csv(model, model_var):\n",
    "    filePath = f'{model}/upstream/upstream_timesteps'\n",
    "    outputpath = f'{model}/upstream_station_all'\n",
    "\n",
    "    file_pattern = f\"{model}/upstream/upstream_timesteps/{model_var}*.map\"\n",
    "\n",
    "    # Get a list of all map files in the folder\n",
    "    file_list = glob.glob(file_pattern)\n",
    "\n",
    "    # Read the station latitude and longitude from a CSV file\n",
    "    loc = pd.read_csv('stationLatLon.csv')\n",
    "    loc = loc[(loc.wmo_reg == 6) & (loc.lat.between(45, 54.5)) & (loc.lon.between(4, 15.5))]\n",
    "\n",
    "    # Iterate over the stations\n",
    "    for station_idx, station_row in loc.iterrows():\n",
    "        lat = station_row['lon']\n",
    "        lon = station_row['lat']\n",
    "        station_no = station_row['grdc_no']\n",
    "\n",
    "        # Create a DataFrame for the current station\n",
    "        extracted_data = pd.DataFrame(columns=['datetime', model_var])\n",
    "\n",
    "        # Iterate over the map files\n",
    "        for file in file_list:\n",
    "            # Extract the base name and date from the file name\n",
    "            filename = os.path.basename(file)\n",
    "            base_name = os.path.splitext(filename)[0]\n",
    "            date_part = base_name.split(\"_\")[-2:]\n",
    "\n",
    "            # Extract the year and month from the date part\n",
    "            year = date_part[0]\n",
    "            month = date_part[1]\n",
    "            date = f'{year}_{month}'\n",
    "\n",
    "            # Read the PCRaster map\n",
    "            pcr_map = pcr.readmap(file)\n",
    "\n",
    "            # Extract the value for the specific location\n",
    "            extracted_value = pcr.cellvalue_by_coordinates(pcr_map, lat, lon)[0]\n",
    "\n",
    "            # Check if the extracted value is NaN\n",
    "            if not pd.isna(extracted_value):\n",
    "                # Add a new row to the DataFrame\n",
    "                extracted_data.loc[len(extracted_data)] = {'datetime': date, model_var: extracted_value}\n",
    "\n",
    "        # Create a file path for the current station\n",
    "        station_csv = os.path.join(outputpath, f'{station_no}_{model_var}.csv')\n",
    "\n",
    "        # Save the DataFrame to a CSV file for the current station\n",
    "        extracted_data.to_csv(station_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e17fbf-3d51-426f-bb15-9e2674f060cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function\n",
    "model = 'meteo'\n",
    "model_var = 'meteo_rain'\n",
    "extract_variables_to_csv(model, model_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af2f909e-aa85-452f-bfd0-517fe708d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function for meteo_tair\n",
    "model = 'meteo'\n",
    "model_var = 'meteo_tair'\n",
    "extract_variables_to_csv(model, model_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da332250-715f-4e7e-8a80-deb64816ad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"pcr\", \"wg3\", \"lis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2ed9b97-f414-4cd9-a967-303702e3f3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished for variables set pcr\n",
      "Finished for variables set wg3\n",
      "Finished for variables set lis\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    \n",
    "    filePath = f'{model}/upstream/upstream_timesteps'\n",
    "    outputPath = f'{model}/upstream_station_all/'\n",
    "    check_dir_or_make(outputPath)\n",
    "    \n",
    "    for file in os.listdir(model):\n",
    "        if file.endswith(\".nc\"):\n",
    "            \n",
    "            var = file.split(\".\")[0]\n",
    "            extract_variables_to_csv(model, var)\n",
    "    print(\"Finished for variables set\", model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
