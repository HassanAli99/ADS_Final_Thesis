{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9912f46-baa9-47d9-98cb-3de8a142a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f9db978-21b1-45a0-b66f-cd0b0e9bf0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 123 \n",
    "random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e31f78b-57c1-49d6-b4c6-05299dba05f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dis(column, area):\n",
    "    time = 24 * 3600\n",
    "    area_m = area*1000000\n",
    "    new_column = column * (time / area_m)\n",
    "    return new_column\n",
    "\n",
    "\n",
    "def normalize_columns_with_dis(df, area):\n",
    "    for column in df.columns:\n",
    "        if 'dis' in column:\n",
    "            df[column] = normalize_dis(df[column], area)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fadfa242-5cfa-46db-a974-690614d04289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_table(stations, filenames, area):\n",
    "    grdc_nos = [str(grdc_no) for grdc_no in stations['grdc_no']]\n",
    "    sub_filenames = [filename for filename in filenames if any(grdc_no in filename for grdc_no in grdc_nos)]\n",
    "    sub_datas = []\n",
    "    \n",
    "    \n",
    "    for filename in sub_filenames:\n",
    "        sub_data = pd.read_csv(filename)\n",
    "        \n",
    "        # Convert 'datetime' column to datetime type\n",
    "        sub_data['datetime'] = pd.to_datetime(sub_data['datetime'])\n",
    "        \n",
    "        # Subset the data based on the datetime range\n",
    "        start_date = pd.to_datetime('1979-01-01')\n",
    "        end_date = pd.to_datetime('2012-12-31')\n",
    "        sub_data = sub_data[(sub_data['datetime'] >= start_date) & (sub_data['datetime'] <= end_date)]\n",
    "        \n",
    "        \n",
    "        sub_datas.append(sub_data)\n",
    "    \n",
    "    sub_table = pd.concat(sub_datas, ignore_index=True)\n",
    "    \n",
    "    return sub_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d530586a-3272-4279-bbdb-f5c1ace27fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "file_path_preds = '../R/data/allpredictors_pcr/'\n",
    "file_list_preds = os.listdir(file_path_preds)\n",
    "file_paths = [os.path.join(file_path_preds, file) for file in file_list_preds]\n",
    "\n",
    "station_info = pd.read_csv(\"../R/data/stations_rhine_elbe.csv\")\n",
    "\n",
    "rhine_stations = station_info.loc[(station_info[\"sub_reg\"] == 6351) | (station_info[\"sub_reg\"] == 6361)]\n",
    "elbe_stations = station_info.loc[(station_info[\"sub_reg\"] == 6401)]\n",
    "maas_stations = station_info.loc[(station_info[\"sub_reg\"] == 6211)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c6be43-2069-4335-970b-a6e707124d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "elbe_stations = elbe_stations[~elbe_stations[\"grdc_no\"].isin([6340300, 6340301])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c65fdb4-abfa-411b-b6f1-437d6405d96c",
   "metadata": {},
   "source": [
    "# Elbe & Maas subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa25ecc-e8ad-4d00-af73-8cce25cefc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Subsample 1...\n",
      "0.7\n",
      "Finished Subsample 1...\n",
      "Sampling Subsample 2...\n",
      "0.7\n",
      "Finished Subsample 2...\n",
      "Sampling Subsample 3...\n",
      "0.7\n",
      "Finished Subsample 3...\n",
      "Sampling Subsample 4...\n",
      "0.7\n",
      "Finished Subsample 4...\n",
      "Sampling Subsample 5...\n",
      "0.7\n",
      "Finished Subsample 5...\n"
     ]
    }
   ],
   "source": [
    "list_ids_rhine = rhine_stations[\"grdc_no\"].to_list()\n",
    "list_ids_all = station_info['grdc_no'].to_list()\n",
    "\n",
    "station_info_rhine = station_info[station_info[\"grdc_no\"].isin([x for x in list_ids_rhine])]\n",
    "setup = \"rhine_pcr\"\n",
    "\n",
    "output_base_dir = f'../R/data/{setup}/'\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "sample_number = 21\n",
    "\n",
    "for subsample in range(1, 6):\n",
    "    output_dir = os.path.join(output_base_dir, f'subsample_{subsample}')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f'Sampling Subsample {subsample}...')\n",
    "    \n",
    "    ## Subset train stations randomly:\n",
    "    train_station_ids = random.sample(list_ids_rhine, sample_number)\n",
    "    train_stations = station_info_rhine[station_info_rhine['grdc_no'].isin([x for x in train_station_ids])]\n",
    "    \n",
    "    # Subset test stations\n",
    "    test_stations =  station_info_rhine[~station_info_rhine[\"grdc_no\"].isin([x for x in train_station_ids])]\n",
    "    \n",
    "    \n",
    "    # Create train table\n",
    "    train_table = subsample_table(train_stations, file_paths, station_info)\n",
    "    train_table['datetime'] = pd.to_datetime(train_table['datetime']).dt.date\n",
    "    \n",
    "    # Create train test\n",
    "    test_table = subsample_table(test_stations, file_paths,station_info)\n",
    "    test_table['datetime'] = pd.to_datetime(test_table['datetime']).dt.date\n",
    "    \n",
    "\n",
    "    nrow_train = train_table.shape[0]\n",
    "    nrow_test = test_table.shape[0]\n",
    "    \n",
    "    ratio_subsamples = nrow_train / (nrow_train + nrow_test)\n",
    "    \n",
    "    print(ratio_subsamples)\n",
    "    \n",
    "    \n",
    "    # Write tables: train_stations, test_stations, train_table\n",
    "    train_stations.to_csv(os.path.join(output_dir, 'train_stations.csv'), index=False)\n",
    "    test_stations.to_csv(os.path.join(output_dir, 'test_stations.csv'), index=False)\n",
    "    train_table.to_csv(os.path.join(output_dir, 'train_table_allpredictors.csv'), index=False)\n",
    "    test_table.to_csv(os.path.join(output_dir, 'test_table_allpredictors.csv'), index=False)\n",
    "\n",
    "\n",
    "\n",
    "    print(f'Finished Subsample {subsample}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c85a938-e92b-4be7-8182-6bedb28a1293",
   "metadata": {},
   "source": [
    "#station_info = pd.read_csv(\"../data/stations_rhine_elbe.csv\")\n",
    "# Random sampling all_stations (70/30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87b4dbf-b3cc-43ff-a63b-7bdef512d972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling Subsample 1...\n",
      "0.6754865051169203\n",
      "Finished Subsample 1...\n",
      "Sampling Subsample 2...\n",
      "0.6934089824486982\n",
      "Finished Subsample 2...\n",
      "Sampling Subsample 3...\n",
      "0.7060289516941514\n",
      "Finished Subsample 3...\n",
      "Sampling Subsample 4...\n",
      "0.6969616628665358\n",
      "Finished Subsample 4...\n",
      "Sampling Subsample 5...\n",
      "0.6981812397263906\n",
      "Finished Subsample 5...\n"
     ]
    }
   ],
   "source": [
    "# Iterate over sub-samples\n",
    "# Path configurations\n",
    "setup = \"all_stations\"\n",
    "\n",
    "output_base_dir = f'../R/data/{setup}/'\n",
    "os.makedirs(output_base_dir, exist_ok=True)\n",
    "\n",
    "for subsample in range(1, 6):\n",
    "    output_dir = os.path.join(output_base_dir, f'subsample_{subsample}')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f'Sampling Subsample {subsample}...')\n",
    "    \n",
    "    ## Subset train stations randomly:\n",
    "    train_stations = random.sample(list(station_info['grdc_no']), 35)\n",
    "    train_stations = station_info[station_info['grdc_no'].isin(train_stations)]\n",
    "    \n",
    "    # Subset test stations\n",
    "    test_stations = station_info[~station_info['grdc_no'].isin(train_stations['grdc_no'])]\n",
    "    \n",
    "    \n",
    "    # Create train table\n",
    "    train_table = subsample_table(train_stations, file_paths, station_info)\n",
    "    train_table['datetime'] = pd.to_datetime(train_table['datetime']).dt.date\n",
    "    \n",
    "    # Create train test\n",
    "    test_table = subsample_table(test_stations, file_paths,station_info)\n",
    "    test_table['datetime'] = pd.to_datetime(test_table['datetime']).dt.date\n",
    "    \n",
    "\n",
    "    nrow_train = train_table.shape[0]\n",
    "    nrow_test = test_table.shape[0]\n",
    "    \n",
    "    ratio_subsamples = nrow_train / (nrow_train + nrow_test)\n",
    "    \n",
    "    print(ratio_subsamples)\n",
    "    \n",
    "    # Sample file paths for test stations\n",
    "    test_file_paths = random.sample(file_paths, k=len(test_stations))\n",
    "    \n",
    "    # Filter file paths for train stations\n",
    "    train_file_paths = [file_path for file_path in file_paths if file_path not in test_file_paths]\n",
    "    \n",
    "    # Write tables: train_stations, test_stations, train_table\n",
    "    train_stations.to_csv(os.path.join(output_dir, 'train_stations.csv'), index=False)\n",
    "    test_stations.to_csv(os.path.join(output_dir, 'test_stations.csv'), index=False)\n",
    "    train_table.to_csv(os.path.join(output_dir, 'train_table_allpredictors.csv'), index=False)\n",
    "    test_table.to_csv(os.path.join(output_dir, 'test_table_allpredictors.csv'), index=False)\n",
    "\n",
    "    # Save test file paths\n",
    "    with open(os.path.join(output_dir, 'test_file_paths.txt'), 'w') as f:\n",
    "        for file_path in test_file_paths:\n",
    "            f.write(file_path + '\\n')\n",
    "    \n",
    "     \n",
    "    # Save train file paths\n",
    "    with open(os.path.join(output_dir, 'train_file_paths.txt'), 'w') as f:\n",
    "        for file_path in train_file_paths:\n",
    "            f.write(file_path + '\\n')\n",
    "\n",
    "    print(f'Finished Subsample {subsample}...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2772a175-8281-47d2-85bb-c7fa0d96d227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup maas_pcr...\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "setup = \"maas_pcr\"  # 2, 3 and 4 => test stations for rhine, elbe, mass respectively\n",
    "\n",
    "output_dir = f'../R/data/{setup}/'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f'Setup {setup}...')\n",
    "\n",
    "# Select test stations\n",
    "if setup == \"elbe_pcr\":\n",
    "    test_stations = elbe_stations\n",
    "elif setup == \"maas_pcr\":\n",
    "    test_stations = maas_stations\n",
    "\n",
    "\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d1ff2245-c83d-4e32-978e-089a0d6574a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8108108108108109\n"
     ]
    }
   ],
   "source": [
    "#station_info[~station_info['grdc_no'].isin(test_stations['grdc_no'])]\n",
    "\n",
    "# Create train stations\n",
    "train_stations = rhine_stations\n",
    "\n",
    "# Create train table\n",
    "train_table = subsample_table(train_stations, file_paths, station_info)\n",
    "train_table['datetime'] = pd.to_datetime(train_table['datetime']).dt.date\n",
    "\n",
    " # Create train test\n",
    "test_table = subsample_table(test_stations, file_paths,station_info)\n",
    "test_table['datetime'] = pd.to_datetime(test_table['datetime']).dt.date\n",
    "\n",
    "\n",
    "nrow_train = train_table.shape[0]\n",
    "nrow_test = test_table.shape[0]\n",
    "\n",
    "ratio_subsamples = nrow_train / (nrow_train + nrow_test)\n",
    "\n",
    "print(ratio_subsamples)\n",
    "\n",
    "# Sample file paths for test stations\n",
    "test_file_paths = random.sample(file_paths, k=len(test_stations))\n",
    "\n",
    "# Filter file paths for train stations\n",
    "train_file_paths = [file_path for file_path in file_paths if file_path not in test_file_paths]\n",
    "\n",
    "# Write tables: train_stations, test_stations, train_table\n",
    "train_stations.to_csv(os.path.join(output_dir, 'train_stations.csv'), index=False)\n",
    "test_stations.to_csv(os.path.join(output_dir, 'test_stations.csv'), index=False)\n",
    "train_table.to_csv(os.path.join(output_dir, 'train_table_allpredictors.csv'), index=False)\n",
    "test_table.to_csv(os.path.join(output_dir, 'test_table_allpredictors.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
